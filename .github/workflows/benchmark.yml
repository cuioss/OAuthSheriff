name: Performance Benchmark

on:
  pull_request:
    branches: [ "main" ]
    types: [ closed ]
  push:
    tags: [ "*" ]
  workflow_dispatch:

# Declare default permissions as read only (principle of least privilege)
permissions:
  contents: read

# Prevent concurrent benchmark runs to avoid interference
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: false  # Don't cancel in-progress runs as benchmarks are expensive

jobs:
  benchmark:
    name: Run JMH Benchmarks
    runs-on: ubuntu-latest
    # Only run on merged PRs, not just closed ones
    if: github.event_name != 'pull_request' || github.event.pull_request.merged == true
    # Add timeout to prevent long-running jobs (increased for integration benchmarks)
    timeout-minutes: 45
    permissions:
      # Needed to upload artifacts
      contents: write

    steps:
      - name: Harden the runner (Audit all outbound calls)
        uses: step-security/harden-runner@5ef0c079ce82195b2a36a210272d6b661572d83e # v2.14.2
        with:
          egress-policy: audit

      - name: Create GitHub App token for deployment
        id: app-token
        uses: actions/create-github-app-token@29824e69f54612133e76f7eaac726eef6c875baf # v2.2.1
        with:
          app-id: ${{ secrets.RELEASE_APP_ID }}
          private-key: ${{ secrets.RELEASE_APP_PRIVATE_KEY }}
          repositories: ${{ github.event.repository.name }},cuioss.github.io
          owner: cuioss

      - name: Checkout code
        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6.0.2
        with:
          fetch-depth: 0  # Fetch all history for proper versioning
          persist-credentials: false  # Prevent token from overriding app token during deploy

      - name: Set up JDK 21
        uses: actions/setup-java@be666c2fcd27ec809703dec50e508c2fdc7f6654 # v5.2.0
        with:
          java-version: '21'
          distribution: 'temurin'
          cache: maven
      
      - name: Cache npm packages
        uses: actions/cache@cdf6c1fa76f9f475f3d7449005a359c84ca0f306 # v5.0.3
        with:
          path: ~/.npm
          key: ${{ runner.os }}-npm-${{ hashFiles('**/package-lock.json', '**/package.json') }}
          restore-keys: |
            ${{ runner.os }}-npm-

      - name: Build oauth-sheriff-core
        run: |
          # Build core module first to ensure test artifact is available for benchmarking
          ./mvnw --no-transfer-progress clean install -DskipTests

      - name: Fetch Previous History
        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6.0.2
        with:
          repository: cuioss/cuioss.github.io
          ref: main
          path: previous-pages
          sparse-checkout: |
            OAuth-Sheriff/benchmarks/micro/history
            OAuth-Sheriff/benchmarks/integration/history
        continue-on-error: true

      - name: Prepare Historical Data for Benchmarks
        run: |
          python3 benchmarking/scripts/benchmark-pages.py prepare-history \
            --previous-pages-dir previous-pages/OAuth-Sheriff/benchmarks \
            --output-dir "${GITHUB_WORKSPACE}/benchmark-history"

      - name: Run Micro Benchmarks
        run: |
          # Run micro benchmarks using configuration from pom.xml
          # Pass history directory as system property for trend calculation
          ./mvnw --no-transfer-progress clean verify -pl benchmarking/benchmark-core -Pbenchmark \
            -Dbenchmark.history.dir="${GITHUB_WORKSPACE}/benchmark-history/micro"
          
          # Verify artifacts were generated
          echo "ðŸ“Š Micro benchmark artifacts generated:"
          ls -la benchmarking/benchmark-core/target/benchmark-results/

      - name: Run Integration Benchmarks with WRK
        run: |
          # Run WRK-based integration benchmarks with native image
          # GitHub Actions has 4 vCPU for public repos, use default profile
          echo "ðŸš€ Running WRK integration benchmarks with native Quarkus..."
          ./mvnw --no-transfer-progress clean verify -pl benchmarking/benchmark-integration-wrk -Pbenchmark \
            -Dbenchmark.history.dir="${GITHUB_WORKSPACE}/benchmark-history/integration"

          # Verify artifacts were generated
          echo "ðŸ“Š Integration benchmark artifacts generated:"
          ls -la benchmarking/benchmark-integration-wrk/target/benchmark-results/

      - name: Assemble benchmark artifacts for deployment
        run: |
          python3 benchmarking/scripts/benchmark-pages.py assemble \
            --micro-results benchmarking/benchmark-core/target/benchmark-results/gh-pages-ready \
            --integration-results benchmarking/benchmark-integration-wrk/target/benchmark-results/gh-pages-ready \
            --previous-pages-dir previous-pages/OAuth-Sheriff/benchmarks \
            --output-dir gh-pages \
            --commit-sha "${{ github.sha }}"

      - name: Upload benchmark results
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: benchmark-results
          path: gh-pages/
          retention-days: 90  # Keep results for 90 days

      - name: Checkout cuioss.github.io for deployment
        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6.0.2
        with:
          repository: cuioss/cuioss.github.io
          path: _pages-deploy
          sparse-checkout: OAuth-Sheriff/benchmarks
          token: ${{ steps.app-token.outputs.token }}

      - name: Deploy to cuioss.github.io
        run: |
          TARGET_DIR="_pages-deploy/OAuth-Sheriff/benchmarks"
          rm -rf "$TARGET_DIR"
          mkdir -p "$TARGET_DIR"
          cp -r gh-pages/* "$TARGET_DIR/"
          cd _pages-deploy
          git config user.name "cuioss-release-bot[bot]"
          git config user.email "cuioss-release-bot[bot]@users.noreply.github.com"
          git add .
          git diff --staged --quiet || git commit -m "Deploy benchmark results from ${{ github.sha }}"
          git push
